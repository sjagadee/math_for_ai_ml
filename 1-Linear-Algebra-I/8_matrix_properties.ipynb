{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix properties\n",
    "\n",
    "Frobenius Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1**2 + 2**2 + 3**2 + 4**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.477225575051661)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X) #same as vector L2 norm also known as Euclidean norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4772)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frobenius norm using pytorch\n",
    "import torch\n",
    "X_pt = torch.tensor([[1, 2], [3, 4.]])\n",
    "torch.norm(X_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.4772257804870605>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frobenius norm using tensorflow\n",
    "import tensorflow as tf\n",
    "X_tf = tf.Variable([[1, 2], [3, 4.]])\n",
    "tf.norm(X_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication (with a Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "(3, 2)\n",
      "[1 2]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3,4], [5,6], [7,8]])\n",
    "\n",
    "b = np.array([1,2])\n",
    "\n",
    "print(A)\n",
    "print(A.shape)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 17, 23])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, b) # technically dot product are between vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 17, 23])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pt = torch.tensor([[3,4], [5,6], [7,8]])\n",
    "b_pt = torch.tensor([1,2])\n",
    "\n",
    "from_np = torch.from_numpy(b)\n",
    "\n",
    "# using pytorch matmul - like dot np.dot() - automatically infers dims in order to perform dot product, matvec, or matrix multiplication\n",
    "torch.matmul(A_pt, b_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([11, 17, 23], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tf = tf.Variable([[3,4], [5,6], [7,8]])\n",
    "b_tf = tf.Variable([1,2])\n",
    "\n",
    "from_np_tf = tf.convert_to_tensor(b, dtype=tf.int32)\n",
    "\n",
    "# matvec - matrix vector multiplication\n",
    "tf.linalg.matvec(A_tf, b_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Matrix-by-)Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "(3, 2)\n",
      "[[1 9]\n",
      " [2 0]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "M1 = np.array([[3,4], [5,6], [7,8]])\n",
    "M2 = np.array([[1,9], [2,0]])\n",
    "\n",
    "print(M1)\n",
    "print(M1.shape)\n",
    "print(M2)\n",
    "print(M2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(M1, M2)\n",
    "\n",
    "# Matix Multiplication is not Commutative M1*M2 != M2*M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 9],\n",
      "        [2, 0]])\n"
     ]
    }
   ],
   "source": [
    "M1_pt = torch.tensor([[3,4], [5,6], [7,8]])\n",
    "M2_pt = torch.tensor([[1,9], [2,0]])\n",
    "\n",
    "print(M1_pt)\n",
    "print(M2_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 27],\n",
       "        [17, 45],\n",
       "        [23, 63]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(M1_pt, M2_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_tf = tf.Variable([[3,4], [5,6], [7,8]])\n",
    "M2_tf = tf.Variable([[1,9], [2,0]])\n",
    "\n",
    "tf.linalg.matmul(M1_tf, M2_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Matrices\n",
    "\n",
    "Properties are:\n",
    "- Square\n",
    "- $X^T$ = $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sym = np.array([[1, 2, 3], [2, 3 ,4], [3, 4, 5]])\n",
    "X_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sym.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sym.T == X_sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity Matrices\n",
    "\n",
    "- Special case of Symmetric Matrix\n",
    "- Every element along diagonal is 1\n",
    "- All other elements are 0\n",
    "- Notation: $I_n$ were n = height or width\n",
    "- n-length vector unchanged if multiplied by $I_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_indentity = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "X_indentity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  3,  5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.tensor([25, 3, 5])\n",
    "x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  3,  5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(X_indentity, x_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Inversion\n",
    "\n",
    "Properties:\n",
    "- Clever, convenient approach for solving linear equations\n",
    "- An alternative to manually solving with substitution or elemination\n",
    "\n",
    "Matrix inverse of $X$ is denoted as $X^{-1}$\n",
    "- Satisfies = $X^{-1} X$ = $I_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  2],\n",
       "       [-5, -3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[4, 2], [-5, -3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1. ],\n",
       "       [-2.5, -2. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_inv = np.linalg.inv(X)\n",
    "X_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, -7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([4, -7])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression formula is $y = Xw$ - where w is the weights through m\n",
    "\n",
    "- we can also write the same regression formula like this $Xw = y$\n",
    "- assuming $X^{-1}$ exists\n",
    "- then, $X^{-1} Xw$ = $X^{-1}y$\n",
    "- We know $X^{-1} X$ = $I_n$\n",
    "- So, $I_n w$ = $X^{-1}y$\n",
    "- any vector multiplied by Identity matrix $I_n$ is itself\n",
    "- Finally, $w$ = $X^{-1}y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  4.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.dot(X_inv, y)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we know the weights, we can use it on the equation\n",
    "y1 = 4 * -1 + 2 * 4\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = -5 * -1 + -3 * 4\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4., -7.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us equate the same to the original equation y = Xw\n",
    "y = np.dot(X, w)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  1.0000],\n",
       "        [-2.5000, -2.0000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse of a matrix in PyTorch and TensorFlow\n",
    "torch.inverse(torch.tensor([[4, 2.], [-5, -3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.4999998,  0.9999998],\n",
       "       [-2.4999995, -1.9999996]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.inv(tf.Variable([[4, 2.], [-5, -3]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix inversion is a nifty trick, but can only be applied to matrix\n",
    "- Matrix is not sigular\n",
    "- That is all columns of matrix must be linearly independent\n",
    "    - Eg: if a column is [1,2] and another column cannot be [2,4] or also [1,2] \n",
    "\n",
    "Where can it be applied:\n",
    "- we appply matrix inversion on square matrix $n_row$ = $n_col$ (vector span = matrix)\n",
    "    - Avoid overdetermination  $n_{row}$ > $n_{col}$ or  $n_{equations}$ > $n_{dimentions}$ \n",
    "    - Avoid underdetermination  $n_{row}$ < $n_{col}$ or  $n_{equations}$ < $n_{dimentions}$ \n",
    "\n",
    "*There are other ways to solve for overdetermined and underdetermined matrices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4,  1],\n",
       "       [-4,  1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Materix inversion with no solution\n",
    "\n",
    "# X = np.array([[-4, 1], [-8, 2]])\n",
    "X = np.array([[-4, 1], [-4, 1]])\n",
    "# X = np.array([[-4, 1], [-3, 6], [6, 8]])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Xinv = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/my_ai_py/lib/python3.12/site-packages/numpy/linalg/_linalg.py:609\u001b[39m, in \u001b[36minv\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    606\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    608\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     ainv = \u001b[43m_umath_linalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/my_ai_py/lib/python3.12/site-packages/numpy/linalg/_linalg.py:104\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "Xinv = np.linalg.inv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal Matrix \n",
    "\n",
    "- Non zero elements along main  diagonal; zeros everywhere else\n",
    "- Identity matrix is an example\n",
    "- If this matrix is a square, can be denoted as diag(**x**) where x is vector of main diagonal elements\n",
    "- Computationally efficient\n",
    "    - Multiplication: $diag(x)y$ = $x \\odot y$\n",
    "    - Inversion: $diag(x)^{-1}$ = $diag[1/x_1,....., 1/x_n]^T$\n",
    "        - Cant' divided by zero so $x$ cannot be zero, here $x$ is diagonal\n",
    "- Can be non-squared matroix and computation is still efficient:\n",
    "    - if $h > w$, simply add zeros to product\n",
    "    - if $h < w$, remove elements from product    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Diagonal matrix\n",
    "\n",
    "X = np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Matrix\n",
    "\n",
    "- In Orthodonal matrices, like orthonormal vectors:\n",
    "    - make up all rows\n",
    "    - make up all columns\n",
    "- This means $A^T A$ = $A A^T$ = $I$\n",
    "- So, let us consider $A A^T$ = $I$\n",
    "    - Here if add inverse on both sides: $A^{-1} A A^T$ = $A^{-1} I$\n",
    "    - A and A inverse cancel out on the left side: $A^T$ = $A^{-1} I$\n",
    "    - When $A^{-1}$ gets multiplied by $I$, it would become just $A^{-1}$: \n",
    "        - $A^T$ = $A^{-1}$ \n",
    "        - Calcualting $A^T$ is cheap, so for orthogonal matrix calculating $A^{-1}$ is also cheap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if I3's columns are orthogonal to each other\n",
    "\n",
    "I_3 = np.eye(3)\n",
    "I_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0.]), array([0., 1., 0.]), array([0., 0., 1.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = I_3[:, 0]\n",
    "c2 = I_3[:, 1]\n",
    "c3 = I_3[:, 2]\n",
    "c1, c2, c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float64(0.0), np.float64(0.0))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.dot(c1, c2)\n",
    "v2 = np.dot(c1, c3)\n",
    "v3 = np.dot(c2, c3)\n",
    "v1, v2, v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(1.0), np.float64(1.0))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if I3's columns has unit norm\n",
    "\n",
    "uc_1 = np.linalg.norm(I_3[:, 0])\n",
    "uc_2 = np.linalg.norm(I_3[:, 1])\n",
    "uc_3 = np.linalg.norm(I_3[:, 2])\n",
    "uc_1, uc_2, uc_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the matrix has mutually orthogonal columns and each column has unit norm, the column vectors of $I_3$ are *orthonormal*. Since\n",
    "$I_3^T$ = $I_3$ this means the rows of $I_3$ must also be orthonormal.\n",
    "\n",
    "Since the columns and rows of $I_3$ are orthonormal, $I_3$ is an orthogonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6667,  0.3333,  0.6667],\n",
       "        [-0.6667,  0.6667,  0.3333],\n",
       "        [ 0.3333,  0.6667, -0.6667]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.tensor([[2/3, 1/3, 2/3], [-2/3, 2/3, 1/3], [1/3, 2/3, -2/3]])\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.6667, -0.6667,  0.3333]),\n",
       " tensor([0.3333, 0.6667, 0.6667]),\n",
       " tensor([ 0.6667,  0.3333, -0.6667]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_c1 = K[:, 0]\n",
    "k_c2 = K[:, 1]\n",
    "k_c3 = K[:, 2]\n",
    "k_c1, k_c2, k_c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(k_c1, k_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(k_c1, k_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(k_c2, k_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(k_c1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(k_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(k_c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this matrix as well we see all the columns are orthogonal to each other and have unit norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6667, -0.6667,  0.3333],\n",
       "        [ 0.3333,  0.6667,  0.6667],\n",
       "        [ 0.6667,  0.3333, -0.6667]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if K transpose \n",
    "\n",
    "K_t = K.T\n",
    "K_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [False,  True, False],\n",
       "        [False, False,  True]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_t == K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K transpose is not equal to K so we can perform to check if K transpose columns are orthogonal to each other and check if K transpose columns has unit norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6667, 0.3333, 0.6667]),\n",
       " tensor([-0.6667,  0.6667,  0.3333]),\n",
       " tensor([ 0.3333,  0.6667, -0.6667]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_t_c1 = K_t[:, 0]\n",
    "K_t_c2 = K_t[:, 1]\n",
    "K_t_c3 = K_t[:, 2]\n",
    "K_t_c1, K_t_c2, K_t_c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(K_t_c1, K_t_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(K_t_c1, K_t_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(K_t_c2, K_t_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(1.), tensor(1.))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check norm of K transpose\n",
    "cn1 = torch.norm(K_t_c1)\n",
    "cn2 = torch.norm(K_t_c2)\n",
    "cn3 = torch.norm(K_t_c3)\n",
    "cn1, cn2, cn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for $K^T$ as well we see that the all the columns are orthogonal to each other and have unit norm.\n",
    "\n",
    "Hence we can conclude that the K is orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can check if $K$ is orthogonal, we can check if $A^T A$ = $I$ for $K$ using a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -3.3114e-09,  3.3114e-09],\n",
       "        [-3.3114e-09,  1.0000e+00,  6.6227e-09],\n",
       "        [ 3.3114e-09,  6.6227e-09,  1.0000e+00]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(K_t, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can confirm that the output of the $K^T K$ is in fact $I$ (identity matrix - diagonals are 1s, other elements close to 0) and Therefore $K$ is orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
