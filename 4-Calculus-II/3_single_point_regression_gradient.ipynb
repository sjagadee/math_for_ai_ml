{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3423776",
   "metadata": {},
   "source": [
    "## Gradient of a Single-Point Regression\n",
    "\n",
    "In this notebook, we calculate the gradient of quadratic cost with respect to a straight-line regression model's parameters. We keep the partial derivatives as simple as possible by limiting the model to handling a single data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605e3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b03d9",
   "metadata": {},
   "source": [
    "Let's use the same data as we did in the [*Regression in PyTorch* notebook](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/regression-in-pytorch.ipynb) as well as for demonstrating the Moore-Penrose Pseudoinverse in the [*Linear Algebra II* notebook](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/2-linear-algebra-ii.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed1d90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7.]) # eg: doseage of a drug for Alzheimers disease\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12370270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8600,  1.3100,  0.6200,  0.3300,  0.0900, -0.6700, -1.2300, -1.3700])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = torch.tensor([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37]) # E.g.: Patient's \"forgetfulness score\"\n",
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597e776",
   "metadata": {},
   "source": [
    "The slope of a line is given by equation $y = mx + b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e182069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(my_x, my_m, my_b):\n",
    "    return my_m * my_x + my_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92580a",
   "metadata": {},
   "source": [
    "Let's initialize $m$ and $b$ with random near-zero values as we did in the _Regression in PyTorch_ notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a99f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([0.9]).requires_grad_()\n",
    "b = torch.tensor([0.1]).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fec2cc",
   "metadata": {},
   "source": [
    "To keep the partial derivatives as simple as possible, let's move forward with a single instance $i$ from the eight possible data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd25135",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "x = xs[i]\n",
    "y = ys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827ef196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(-1.3700))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9311d",
   "metadata": {},
   "source": [
    "**Step 1:** Forward Pass\n",
    "\n",
    "We can flow the scalar tensor $x$ through our regression model to produce $\\hat y$, an estimate of $y$. Prior to any model training, this is an arbitrary estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3368593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = regression(x, m, b)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac391c2",
   "metadata": {},
   "source": [
    "**Step 2:** Compare $\\hat y$ with true y to calculate cost $C$\n",
    "\n",
    "In the regression in pytorch notebook, we used mean-squared error, which averages quadratic cost over multiple data points. With single data point, here we can use quadratic cost alone. It is defined by\n",
    "\n",
    "$C = (\\hat y - y)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a37b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(my_yhat, my_y):\n",
    "    return (my_yhat - my_y) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45adff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([60.3729], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = squared_error(yhat, y)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cccc67",
   "metadata": {},
   "source": [
    "**Step 3:** Use autodiff to calculate gradient of $C$ w.r.t. parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355614d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75311f",
   "metadata": {},
   "source": [
    "The partial derivative of $C$ with respect to $m (\\frac{\\partial C}{\\partial m})$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d524d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([108.7800])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045004d3",
   "metadata": {},
   "source": [
    "The partial derivative of $C$ with respect to $b (\\frac{\\partial C}{\\partial b})$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eede09e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.5400])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0a7f3",
   "metadata": {},
   "source": [
    "From the notes here we derive $\\frac{\\partial C}{\\partial m}$ and $\\frac{\\partial C}{\\partial b}$\n",
    "\n",
    "$\\frac{\\partial C}{\\partial m} = 2x(\\hat y - y)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5cf5d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(108.7800)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * x * (yhat.item() - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca2505",
   "metadata": {},
   "source": [
    "$\\frac{\\partial C}{\\partial b} = 2 (\\hat y - y)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5621a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.5400)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (yhat.item() - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab4e97",
   "metadata": {},
   "source": [
    "### The Gradient of Cost, $\\nabla C$\n",
    "\n",
    "The gradient of cost, which is symbolized $\\nabla C$ (pronounced \"nabla C\"), is a vector of all the partial derivatives of $C$ with respect to each of the individual model parameters: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c14987",
   "metadata": {},
   "source": [
    "$\\nabla C = \\nabla_p C = \\left[ \\frac{\\partial{C}}{\\partial{p_1}}, \\frac{\\partial{C}}{\\partial{p_2}}, \\cdots, \\frac{\\partial{C}}{\\partial{p_n}} \\right]^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7001a",
   "metadata": {},
   "source": [
    "In this case, there are only two parameters, $b$ and $m$:\n",
    "\n",
    "$\\nabla C = \\left[ \\frac{\\partial{C}}{\\partial{b}}, \\frac{\\partial{C}}{\\partial{m}} \\right]^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2dbc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.5400],\n",
       "        [108.7800]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3f738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
